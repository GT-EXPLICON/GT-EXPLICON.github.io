<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>GT XPLICON</title>
<meta http-equiv="Content-Language" content="English" />
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<link rel="stylesheet" type="text/css" href="style.css" media="screen" />
</head>
<body>

<div id="wrap">

<div id="header">
<h1><a href="#">GDR RADIA -- Groupe de Travail Explicabilité et Confiance</a></h1>
<h2>XPLICON</h2>
</div>


<div id="contentbar"> 

<div class="contentbarleft">

</div>

<div class="contentbarright">

</div>

</div>

<div id="content">

<div class="right"> 

<h2><a href="#">A propos</a></h2>

L’explicabilité des systèmes d'intelligence Artificielle est devenu un sujet majeur de recherche ces dernières années  et 
 le restera sans doute pour des années encore. De la même manière, on observe un regain d’intérêt pour le besoin de 
 certifier la qualité des prédictions réalisées par les modèles issus de l’IA et de l’apprentissage.
 Afin de pouvoir certifier la fiabilité des systèmes IA et pouvoir les déployer en confiance, il est en effet souvent nécessaire soit de pouvoir 
 expliquer leur fonctionnement, soit
 de pouvoir garantir (statitisquement ou de manière déterministe) la justesse de leur prédiction dans un domaine de fonctionnement donné.
 
 <br> <br>
 
 Ces deux sujets de recherche s’inscrivent dans l’objectif plus général d’obtenir une “IA de confiance” (trustworthy AI en anglais),
 qui englobe en plus d’autres sujets comme la privacité des données ou encore l’éthique des systèmes d’IA, mais ces
 derniers sont soit assez éloigné du coeur scientifique du GDR (privacité des données), 
 soit doit être traitée avec une vision inter-disciplinaire (notions d’éthique et de morale). Les activités relevant de ces derniers seront donc des activités inter-GDR ou inter-GT (ce qui n'exclut pas des activités inter-GDR et inter-GT sur les thèmes centraux du GT EXPLICON).
 
 <br> <br>
 
 
 Le GT EXPLICON se concentrera donc en priorité sur ces deux aspects que sont 
 l’explicabilité et les garanties de qualité des modèles fournis. 
 
 


 <br> 
 



<br /><br />
 <center>
<img src="images/logo.png" height="200" width="240" alt="LOGO" />
 </center>
<br /><br />

<h2><a href="#">Responsbles du GT</a></h2>

<br>


<ul>
<li>
    Sébastien Destercke est ingénieur (2004) de la Faculté Polytechnique de Mons de Belgium. Il a obtenu sa thèse en 2008, 
 à l'université Paul Sabatier de Toulouse. Il a ensuite été ingénieur de recherche au CIRAD (institut de recherche en agronomie pour les pays en voie de développement), où il travaillait sur l'aide à la décision. Il a ensuite intégré le laboratoire Heudiasyc (Compiègne) en tant que chercheur CNRS. Ses recherches portent principalement sur le traitement (modélisation, raisonnement, apprentissage) des incertitudes sévères aux moyens d'approches probabilistes imprécises (théories des possibilité, de l'évidence, ensembles de probabilités, etc.). Il est actuellement responsable de l'équipe CID d'Heudiasyc, et le titulaire de la chaire SAFE AI.
</li>

<br>

<li>
    Wassila Ouerdane est Maître de conférences en informatique à CentraleSupélec, Université Paris-Saclay  
 depuis 2010 et Habilité à Diriger des Recherches (HDR) 
 depuis 2022. Ellest est membre 
 du laboratoire MICS, 
 au sein du Groupe de recherche LOGIMICS depuis février 2019. 
 Auparavant, elle était au laboratoire de Génie Industriel de CentraleSupélec (Sept. 2010- Janvier 2019). 
 Elle est titulaire d'un doctorat en informatique de l'Université de Paris Dauphine obtenu en 2009. Ses activités de recherche 
 sont à l'intersection de deux domaines : 
 L'Intelligence Artificielle et la Théorie de la Décision. 
 Elle s'intéresse aux questions liées à la représentation des connaissances et du raisonnement dans le contexte de l'IA explicable, dans le but 
 d'utiliser des outils formels de l'IA et de la théorie de la décision pour à la fois spécifier 
 le raisonnement des agents (résolution de conflits, explication de décisions, etc.) et faciliter l'interaction des agents (protocole de dialogue). 


</li>

</ul>
 
 <br>
 <br>
 

<h2><a href="#">Contacts</a></h2>
 
 Pour toute question relative au GT, n'hésitez pas à nous envoyer un mot à cette adress: gt.explicon(at)gmail(dot)com

</div>

<div class="left"> 

<h2>Menu</h2>

<ul>
    <li><a href="index.html" class="active">ACCUEIL</a></li>
    <li><a href="resume.html">PERSPECTIVES & DEFIS</a></li> 
    <li><a href="activities.html">EVENEMENTS</a></li> 
    <li><a href="members.html">MEMBRES</a></li> 
     </ul>



<h2>Archives Evénements</h2>
<ul>
<li><a href="#">January 2023</a></li> 
</ul>

</div>


<div style="clear: both;"> </div>

</div>

<div id="footer">
Designed by <a href="http://www.free-css-templates.com/">Free CSS Templates</a>, Thanks to <a href="http://www.openwebdesign.org/">Web Design Dubai</a>
</div>

</div>

</body>
</html>
